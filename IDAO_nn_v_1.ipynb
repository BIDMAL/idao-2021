{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azAO0fJdqDE6"
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L__XKNl8PPJ"
   },
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import print_function, division\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.ion()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchsummary\n",
    "from torch.utils.data import datasets, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5344,
     "status": "ok",
     "timestamp": 1615569847942,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "gN4sqzGEA-eG",
    "outputId": "743487b7-934a-4018-a0bb-8ea1046b159f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 224\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlOxz93IBhBC"
   },
   "source": [
    "# Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZMhU0i1sYtt"
   },
   "source": [
    "## Модель `create_nn_v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "drjr84ONDd5M"
   },
   "outputs": [],
   "source": [
    "data_dir = './data/classed_nrj_train/'\n",
    "test_dir = './data/test2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Rng9f-4qFJm5"
   },
   "outputs": [],
   "source": [
    "#Набор трансформаций для обучающей выборки\n",
    "train_transforms = transforms.Compose([transforms.CenterCrop(224), \n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.RandomVerticalFlip(p=0.5),\n",
    "                                       transforms.RandomRotation(degrees=(45, 90)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           [0.485, 0.456, 0.406],\n",
    "                                            [0.229, 0.224, 0.225])\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4NhX-_IUFgPx"
   },
   "outputs": [],
   "source": [
    "#Набор трансформаций для валидационной выборки\n",
    "valid_transforms = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           [0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E1ETYBjuFfjt"
   },
   "outputs": [],
   "source": [
    "#Набор трансформаций для тестовой выборки\n",
    "test_transforms = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(\n",
    "                                          [0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "s5bktRR8tCbO"
   },
   "outputs": [],
   "source": [
    "#Объявляю функцию загрузчика с аргументами:\n",
    "#Директория, Размер батча, Набор трансформаций для тренировочной выборки,\n",
    "#Набор трансформаций для валидационной выборки, Размер валидационной выборки\n",
    "def load_split_train_valid(datadir,\n",
    "                           batch_size,\n",
    "                           train_transforms,\n",
    "                           valid_transforms,\n",
    "                           valid_size): \n",
    "    \n",
    "    #Загрузчик для тренировочной выборки\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    #Загрузчик для тренировочной выборки\n",
    "    val_data = datasets.ImageFolder(datadir,\n",
    "                    transform=valid_transforms)\n",
    "    #Код для разделения на трейн и тест в указанном соотношении\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    trainloader = DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=batch_size)\n",
    "    valloader = DataLoader(val_data,\n",
    "                   sampler=val_sampler, batch_size=batch_size)\n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43682,
     "status": "ok",
     "timestamp": 1615569886302,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "nMV_UDtxtQhS",
    "outputId": "700674f7-61ca-4851-89a7-fbb2fc10f417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '20', '3', '30', '6']\n",
      "['1', '10', '20', '3', '30', '6']\n",
      "166\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "#Получаю тренировочный и валидационный генераторы\n",
    "train_loader, val_loader = load_split_train_valid(datadir=data_dir,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           train_transforms=train_transforms,\n",
    "                           valid_transforms=valid_transforms,\n",
    "                           valid_size = .2)\n",
    "#Проверяю результаты работы генераторов\n",
    "print(train_loader.dataset.classes)\n",
    "print(val_loader.dataset.classes)\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HehuufC8EQvY"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module): \n",
    "        def __init__(self):\n",
    "            super(ConvNet, self).__init__()\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "            self.drop1 = nn.Dropout2d(p=0.25)\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "            self.drop2 = nn.Dropout2d(p=0.25)\n",
    "            self.conv3 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "            self.drop3 = nn.Dropout2d(p=0.25)\n",
    "            self.conv4 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(18432, 2048),\n",
    "                nn.BatchNorm1d(2048),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.fc2 = nn.Sequential(\n",
    "                nn.Linear(2048, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.out = nn.Linear(1024, 6)\n",
    "            \n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    m.weight.data = nn.init.xavier_uniform_(m.weight.data,gain=nn.init.calculate_gain('relu'))\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.drop1(self.conv1(x))\n",
    "            x = self.drop2(self.conv2(x))\n",
    "            x = self.drop3(self.conv3(x))\n",
    "            x = self.conv4(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.out(x)\n",
    "\n",
    "            return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54122,
     "status": "ok",
     "timestamp": 1615569896755,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "6c8Aj6fnEQ-7",
    "outputId": "1a8f3bb2-5144-452c-ef3e-694c1c264b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop1): Dropout2d(p=0.25, inplace=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop2): Dropout2d(p=0.25, inplace=False)\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop3): Dropout2d(p=0.25, inplace=False)\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=18432, out_features=2048, bias=True)\n",
      "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (out): Linear(in_features=1024, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "print(net)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4374997,
     "status": "ok",
     "timestamp": 1615574217641,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "nyHS2dE7Eh9A",
    "outputId": "f6378972-f626-4932-bc55-19d25858ee67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/166], Loss: 2.0854, Accuracy: 22.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [01:15<11:22, 75.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/166], Loss: 0.2361, Accuracy: 90.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [02:29<09:56, 74.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/166], Loss: 0.0871, Accuracy: 97.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [03:42<08:35, 73.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/166], Loss: 0.0565, Accuracy: 98.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [04:54<07:19, 73.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/166], Loss: 0.0347, Accuracy: 98.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [06:08<06:08, 73.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/166], Loss: 0.0256, Accuracy: 99.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [07:20<04:51, 72.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/166], Loss: 0.0237, Accuracy: 99.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [08:33<03:39, 73.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/166], Loss: 0.0354, Accuracy: 99.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [09:47<02:26, 73.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/166], Loss: 0.0164, Accuracy: 99.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [11:00<01:13, 73.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/166], Loss: 0.0311, Accuracy: 99.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [12:14<00:00, 73.41s/it]\n"
     ]
    }
   ],
   "source": [
    "#Задаю функцию потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Задаю оптимизатор\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "    #Прямой запуск\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "            \n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #Обратное распространение и оптимизатор\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Отслеживание точности\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += (predicted == labels).sum().item()\n",
    "        processed_data += images.size(0)\n",
    "\n",
    "\n",
    "    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format(epoch + 1, EPOCHS, i + 1, total_step, running_loss / processed_data,\n",
    "                  (running_corrects / processed_data) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5285003,
     "status": "ok",
     "timestamp": 1615575127650,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "y7pu61gXIZuW",
    "outputId": "69a2cf7c-cd97-49c8-ffed-a2f93870b730"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:11<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 99.58584337349397 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Проверка на валидационной выборке\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(val_loader):\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Val Accuracy of the model on the test images: {} %'\n",
    "              .format((correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.ImageFolder(test_dir,\n",
    "                transform=test_transforms)\n",
    "\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "filenames = [line[0].split('\\\\')[1].split('.')[0] for line in test_data.imgs]\n",
    "pred2class = [float(n) for n in train_loader.dataset.classes]\n",
    "dict_pred = defaultdict(list)\n",
    "dict_pred[\"id\"] = filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (img, name) in enumerate(iter(test_loader)):\n",
    "        outputs = net(img)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.cpu()\n",
    "        predicted = [pred2class[pred] for pred in predicted]\n",
    "        dict_pred[\"classification_predictions\"].extend(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(dict_pred, columns=[\"id\", \"regression_predictions\"])\n",
    "data_frame.to_csv('./submissions/submission_tryCNN_reg.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMQnaLY8Fvtx3BvU8HKak4h",
   "collapsed_sections": [],
   "mount_file_id": "1Hm-GAvY9DCwU7lnahqSaDjd_nWjMddgK",
   "name": "IDAO_nn_v_1.ipynb",
   "provenance": [
    {
     "file_id": "1FjssVhc6irYTa5Y8535sFyQBuhq2hW6d",
     "timestamp": 1615543154453
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
