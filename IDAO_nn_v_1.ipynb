{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azAO0fJdqDE6"
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L__XKNl8PPJ"
   },
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import print_function, division\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.ion()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchsummary\n",
    "from torch.utils.data import datasets, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5344,
     "status": "ok",
     "timestamp": 1615569847942,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "gN4sqzGEA-eG",
    "outputId": "743487b7-934a-4018-a0bb-8ea1046b159f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 224\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlOxz93IBhBC"
   },
   "source": [
    "# Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZMhU0i1sYtt"
   },
   "source": [
    "## Модель `create_nn_v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "drjr84ONDd5M"
   },
   "outputs": [],
   "source": [
    "data_dir = './data/classed_nrj_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Rng9f-4qFJm5"
   },
   "outputs": [],
   "source": [
    "#Набор трансформаций для обучающей выборки\n",
    "train_transforms = transforms.Compose([transforms.CenterCrop(224), \n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.RandomVerticalFlip(p=0.5),\n",
    "                                       transforms.RandomRotation(degrees=(45, 90)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           [0.485, 0.456, 0.406],\n",
    "                                            [0.229, 0.224, 0.225])\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4NhX-_IUFgPx"
   },
   "outputs": [],
   "source": [
    "#Набор трансформаций для валидационной выборки\n",
    "valid_transforms = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           [0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "E1ETYBjuFfjt"
   },
   "outputs": [],
   "source": [
    "#Набор трансформаций для тестовой выборки\n",
    "test_transforms = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(\n",
    "                                          [0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "s5bktRR8tCbO"
   },
   "outputs": [],
   "source": [
    "#Объявляю функцию загрузчика с аргументами:\n",
    "#Директория, Размер батча, Набор трансформаций для тренировочной выборки,\n",
    "#Набор трансформаций для валидационной выборки, Размер валидационной выборки\n",
    "def load_split_train_valid(datadir,\n",
    "                           batch_size,\n",
    "                           train_transforms,\n",
    "                           valid_transforms,\n",
    "                           valid_size): \n",
    "    \n",
    "    #Загрузчик для тренировочной выборки\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    #Загрузчик для тренировочной выборки\n",
    "    test_data = datasets.ImageFolder(datadir,\n",
    "                    transform=valid_transforms)\n",
    "    #Код для разделения на трейн и тест в указанном соотношении\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=batch_size)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=batch_size)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43682,
     "status": "ok",
     "timestamp": 1615569886302,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "nMV_UDtxtQhS",
    "outputId": "700674f7-61ca-4851-89a7-fbb2fc10f417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '20', '3', '30', '6']\n",
      "['1', '10', '20', '3', '30', '6']\n",
      "664\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "#Получаю тренировочный и валидационный генераторы\n",
    "train_loader, val_loader = load_split_train_valid(datadir=data_dir,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           train_transforms=train_transforms,\n",
    "                           valid_transforms=valid_transforms,\n",
    "                           valid_size = .2)\n",
    "#Проверяю результаты работы генераторов\n",
    "print(train_loader.dataset.classes)\n",
    "print(val_loader.dataset.classes)\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HehuufC8EQvY"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module): \n",
    "        def __init__(self):\n",
    "            super(ConvNet, self).__init__()\n",
    "            self.c1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "            self.c2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "            self.c3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "            self.fc1 = nn.Linear(in_features=6272, out_features=1024)\n",
    "            self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
    "            self.fc3 = nn.Linear(in_features=512, out_features=256)\n",
    "            self.fc4 = nn.Linear(in_features=256, out_features=6)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = F.relu(F.max_pool2d(self.c1(x), 3))\n",
    "            x = F.relu(F.max_pool2d(self.c2(x), 3))\n",
    "            x = F.relu(F.max_pool2d(self.c3(x), 3))\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "\n",
    "            return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54122,
     "status": "ok",
     "timestamp": 1615569896755,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "6c8Aj6fnEQ-7",
    "outputId": "1a8f3bb2-5144-452c-ef3e-694c1c264b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (c1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (c2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (c3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=6272, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "print(net)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4374997,
     "status": "ok",
     "timestamp": 1615574217641,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "nyHS2dE7Eh9A",
    "outputId": "f6378972-f626-4932-bc55-19d25858ee67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/664], Loss: 1.3224, Accuracy: 62.50%\n",
      "Epoch [1/10], Step [200/664], Loss: 0.2548, Accuracy: 93.75%\n",
      "Epoch [1/10], Step [300/664], Loss: 0.3418, Accuracy: 81.25%\n",
      "Epoch [1/10], Step [400/664], Loss: 0.2114, Accuracy: 93.75%\n",
      "Epoch [1/10], Step [500/664], Loss: 0.0807, Accuracy: 100.00%\n",
      "Epoch [1/10], Step [600/664], Loss: 0.0549, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▏                                                                         | 1/10 [04:21<39:17, 261.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/664], Loss: 0.0112, Accuracy: 100.00%\n",
      "Epoch [2/10], Step [200/664], Loss: 0.6988, Accuracy: 81.25%\n",
      "Epoch [2/10], Step [300/664], Loss: 0.0315, Accuracy: 100.00%\n",
      "Epoch [2/10], Step [400/664], Loss: 0.2736, Accuracy: 93.75%\n",
      "Epoch [2/10], Step [500/664], Loss: 0.0036, Accuracy: 100.00%\n",
      "Epoch [2/10], Step [600/664], Loss: 0.3615, Accuracy: 87.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 2/10 [05:20<18:59, 142.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/664], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [3/10], Step [200/664], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [3/10], Step [300/664], Loss: 0.0268, Accuracy: 100.00%\n",
      "Epoch [3/10], Step [400/664], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [3/10], Step [500/664], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [3/10], Step [600/664], Loss: 0.0133, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 3/10 [06:17<12:04, 103.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/664], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [4/10], Step [200/664], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [4/10], Step [300/664], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [4/10], Step [400/664], Loss: 0.0112, Accuracy: 100.00%\n",
      "Epoch [4/10], Step [500/664], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [4/10], Step [600/664], Loss: 0.0048, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [07:14<08:30, 85.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/664], Loss: 0.0370, Accuracy: 100.00%\n",
      "Epoch [5/10], Step [200/664], Loss: 0.0050, Accuracy: 100.00%\n",
      "Epoch [5/10], Step [300/664], Loss: 0.0017, Accuracy: 100.00%\n",
      "Epoch [5/10], Step [400/664], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [5/10], Step [500/664], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [5/10], Step [600/664], Loss: 0.3219, Accuracy: 93.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [08:12<06:16, 75.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/664], Loss: 0.0139, Accuracy: 100.00%\n",
      "Epoch [6/10], Step [200/664], Loss: 0.0202, Accuracy: 100.00%\n",
      "Epoch [6/10], Step [300/664], Loss: 0.0111, Accuracy: 100.00%\n",
      "Epoch [6/10], Step [400/664], Loss: 0.0080, Accuracy: 100.00%\n",
      "Epoch [6/10], Step [500/664], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [6/10], Step [600/664], Loss: 0.0002, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [09:09<04:36, 69.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/664], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [7/10], Step [200/664], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [7/10], Step [300/664], Loss: 0.0028, Accuracy: 100.00%\n",
      "Epoch [7/10], Step [400/664], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [7/10], Step [500/664], Loss: 0.0081, Accuracy: 100.00%\n",
      "Epoch [7/10], Step [600/664], Loss: 0.0013, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [10:06<03:15, 65.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/664], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [8/10], Step [200/664], Loss: 0.0036, Accuracy: 100.00%\n",
      "Epoch [8/10], Step [300/664], Loss: 0.0491, Accuracy: 93.75%\n",
      "Epoch [8/10], Step [400/664], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [8/10], Step [500/664], Loss: 0.0983, Accuracy: 93.75%\n",
      "Epoch [8/10], Step [600/664], Loss: 0.0075, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [11:04<02:05, 62.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/664], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [9/10], Step [200/664], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [9/10], Step [300/664], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [9/10], Step [400/664], Loss: 0.5328, Accuracy: 93.75%\n",
      "Epoch [9/10], Step [500/664], Loss: 0.0058, Accuracy: 100.00%\n",
      "Epoch [9/10], Step [600/664], Loss: 0.0009, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [12:02<01:01, 61.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/664], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [10/10], Step [200/664], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [10/10], Step [300/664], Loss: 0.0082, Accuracy: 100.00%\n",
      "Epoch [10/10], Step [400/664], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [10/10], Step [500/664], Loss: 0.0080, Accuracy: 100.00%\n",
      "Epoch [10/10], Step [600/664], Loss: 0.0018, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [12:59<00:00, 77.98s/it]\n"
     ]
    }
   ],
   "source": [
    "#Задаю функцию потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Задаю оптимизатор\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "    #Прямой запуск\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "            \n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        #Обратное распространение и оптимизатор\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Отслеживание точности\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "            .format(epoch + 1, EPOCHS, i + 1, total_step, loss.item(),\n",
    "                                  (correct / total) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5285003,
     "status": "ok",
     "timestamp": 1615575127650,
     "user": {
      "displayName": "Кирилл Киселев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUPWucn1Zbt8lx0aRqSpB9ITz_kuO8GREom0axXA=s64",
      "userId": "11298311328855194961"
     },
     "user_tz": -300
    },
    "id": "y7pu61gXIZuW",
    "outputId": "69a2cf7c-cd97-49c8-ffed-a2f93870b730"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [00:55<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 99.73644578313254 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Проверка на валидационной выборке\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(val_loader):\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the test images: {} %'\n",
    "              .format((correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ca_JButXd1py"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMQnaLY8Fvtx3BvU8HKak4h",
   "collapsed_sections": [],
   "mount_file_id": "1Hm-GAvY9DCwU7lnahqSaDjd_nWjMddgK",
   "name": "IDAO_nn_v_1.ipynb",
   "provenance": [
    {
     "file_id": "1FjssVhc6irYTa5Y8535sFyQBuhq2hW6d",
     "timestamp": 1615543154453
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
