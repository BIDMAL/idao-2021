{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azAO0fJdqDE6"
   },
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5L__XKNl8PPJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm_notebook\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN4sqzGEA-eG",
    "outputId": "a96646ea-a502-4219-c98e-26498015fa36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 224\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "SEED = 69\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "data_dir = './data/classed_type_train/'\n",
    "test_dir = './data/test2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZMhU0i1sYtt"
   },
   "source": [
    "## Модель `cnn_Bv1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Rng9f-4qFJm5"
   },
   "outputs": [],
   "source": [
    "#Набор трансформаций для обучающей выборки\n",
    "train_transforms = transforms.Compose([transforms.CenterCrop(192), \n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.RandomVerticalFlip(p=0.5),\n",
    "                                       transforms.RandomRotation(45),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           [0.485, 0.456, 0.406],\n",
    "                                            [0.229, 0.224, 0.225])\n",
    "                                       ])\n",
    "\n",
    "#Набор трансформаций для валидационной выборки\n",
    "valid_transforms = transforms.Compose([transforms.CenterCrop(192),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           [0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                                       ])\n",
    "\n",
    "#Набор трансформаций для тестовой выборки\n",
    "test_transforms = transforms.Compose([transforms.CenterCrop(192),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(\n",
    "                                          [0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s5bktRR8tCbO"
   },
   "outputs": [],
   "source": [
    "#Объявляю функцию загрузчика с аргументами:\n",
    "#Директория, Размер батча, Набор трансформаций для тренировочной выборки,\n",
    "#Набор трансформаций для валидационной выборки, Размер валидационной выборки\n",
    "def load_split_train_valid(datadir,\n",
    "                           batch_size,\n",
    "                           train_transforms,\n",
    "                           valid_transforms,\n",
    "                           valid_size): \n",
    "    \n",
    "    #Загрузчик для тренировочной выборки\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    #Загрузчик для тренировочной выборки\n",
    "    val_data = datasets.ImageFolder(datadir,\n",
    "                    transform=valid_transforms)\n",
    "    #Код для разделения на трейн и тест в указанном соотношении\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    trainloader = DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=batch_size)\n",
    "    valloader = DataLoader(val_data,\n",
    "                   sampler=val_sampler, batch_size=batch_size)\n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMV_UDtxtQhS",
    "outputId": "5d0ad4cc-85fc-49af-ca2b-b29638526c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ER', 'NR']\n",
      "['ER', 'NR']\n",
      "166\n",
      "42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ER': 0, 'NR': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Получаю тренировочный и валидационный генераторы\n",
    "train_loader, val_loader = load_split_train_valid(datadir=data_dir,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           train_transforms=train_transforms,\n",
    "                           valid_transforms=valid_transforms,\n",
    "                           valid_size = .2)\n",
    "#Проверяю результаты работы генераторов\n",
    "print(train_loader.dataset.classes)\n",
    "print(val_loader.dataset.classes)\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "train_loader.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HehuufC8EQvY"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module): \n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "            self.drop1 = nn.Dropout2d(p=0.25)\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "            self.drop2 = nn.Dropout2d(p=0.25)\n",
    "            self.conv3 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "            self.drop3 = nn.Dropout2d(p=0.25)\n",
    "            self.conv4 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(12800, 2048),\n",
    "                nn.BatchNorm1d(2048),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.fc2 = nn.Sequential(\n",
    "                nn.Linear(2048, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.out = nn.Linear(1024, 2)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.drop1(self.conv1(x))\n",
    "            x = self.drop2(self.conv2(x))\n",
    "            x = self.drop3(self.conv3(x))\n",
    "            x = self.conv4(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.out(x)\n",
    "\n",
    "            return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyHS2dE7Eh9A",
    "outputId": "d5e23adf-2410-44ce-998d-285dd7f8d460"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6ffc93dc4e46f49168b6ae0ac7a8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2660327b5c743cdbceba5d924b19f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=166.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-09f37bc25438>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Обратное распространение и оптимизатор\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "net = net.to(device)\n",
    "\n",
    "#Задаю функцию потерь\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Задаю оптимизатор\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.5)\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "    for i, (images, labels) in enumerate(tqdm_notebook(train_loader)):\n",
    "        # Прямой запуск\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)            \n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Обратное распространение и оптимизатор\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Отслеживание точности\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        \n",
    "        running_loss += loss.item() * total\n",
    "        running_corrects += (predicted == labels).sum().item()\n",
    "        processed_data += total\n",
    "    scheduler.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "          .format(epoch + 1, EPOCHS, running_loss / processed_data,\n",
    "                  (running_corrects / processed_data) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch [20/20], Loss: 0.0099, Accuracy: 99.70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCjSokZcG9cy",
    "outputId": "333cf48e-e982-446a-d6b7-ef31bc99364b"
   },
   "outputs": [],
   "source": [
    "#Проверка на валидационной выборке\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm_notebook(val_loader):\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the test images: {} %'\n",
    "              .format((correct / total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_data = datasets.ImageFolder(test_dir,\n",
    "                transform=test_transforms)\n",
    "\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)\n",
    "filenames = [line[0].split('\\\\')[1].split('.')[0] for line in test_data.imgs]\n",
    "dict_pred = defaultdict(list)\n",
    "dict_pred[\"id\"] = filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (img, name) in enumerate(iter(test_loader)):\n",
    "        img = img.to(device)\n",
    "        outputs = net(img)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = list(map(int, predicted.cpu()))\n",
    "        dict_pred[\"classification_predictions\"].extend(predicted)\n",
    "print(len(dict_pred['id']))\n",
    "print(len(dict_pred['classification_predictions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_frame = pd.DataFrame(dict_pred, columns=[\"id\", \"classification_predictions\"])\n",
    "data_frame.to_csv('./submissions/cnn-v3-type.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IDAO_nn_NR_ER_v_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
