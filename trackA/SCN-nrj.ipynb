{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brazilian-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "australian-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_MODES = ['train', 'val', 'test']\n",
    "RESCALE_SIZE = 160\n",
    "EPOCHS = 21\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "SEED = 69\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "device = torch.device(device)\n",
    "\n",
    "train_type_dir = '../data/train/type'\n",
    "train_nrj_dir = '../data/train/nrj'\n",
    "test_dir = '../data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radio-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.CenterCrop(RESCALE_SIZE), \n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.RandomVerticalFlip(p=0.5),\n",
    "                                       transforms.RandomRotation(45),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           [0.485, 0.456, 0.406],\n",
    "                                            [0.229, 0.224, 0.225])\n",
    "                                       ])\n",
    "\n",
    "testval_transforms = transforms.Compose([transforms.CenterCrop(RESCALE_SIZE),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           [0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opposite-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_train_valid(datadir, batch_size, train_transforms, valid_transforms, valid_size):\n",
    "\n",
    "    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n",
    "    val_data = datasets.ImageFolder(datadir, transform=testval_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    trainloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    valloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)   \n",
    "\n",
    "    return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classical-borough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ER', 'NR']\n",
      "['ER', 'NR']\n",
      "166\n",
      "42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ER': 0, 'NR': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_type_loader, val_type_loader = load_split_train_valid(datadir=train_type_dir,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           train_transforms=train_transforms,\n",
    "                           valid_transforms=testval_transforms,\n",
    "                           valid_size = .2)\n",
    "\n",
    "print(train_type_loader.dataset.classes)\n",
    "print(val_type_loader.dataset.classes)\n",
    "print(len(train_type_loader))\n",
    "print(len(val_type_loader))\n",
    "train_type_loader.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranking-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '20', '3', '30', '6']\n",
      "['1', '10', '20', '3', '30', '6']\n",
      "166\n",
      "42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': 0, '10': 1, '20': 2, '3': 3, '30': 4, '6': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nrj_loader, val_nrj_loader = load_split_train_valid(datadir=train_nrj_dir,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           train_transforms=train_transforms,\n",
    "                           valid_transforms=testval_transforms,\n",
    "                           valid_size = .2)\n",
    "\n",
    "print(train_nrj_loader.dataset.classes)\n",
    "print(val_nrj_loader.dataset.classes)\n",
    "print(len(train_nrj_loader))\n",
    "print(len(val_nrj_loader))\n",
    "train_nrj_loader.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metropolitan-drunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 16560)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(test_dir, testval_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "len(test_loader), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "protected-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "signal-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler, num_epochs, train_dataloader, val_dataloader):\n",
    "    hystory_loss_train = []\n",
    "    hystory_loss_val = []\n",
    "\n",
    "    hystory_acc_train = []\n",
    "    hystory_acc_val = []  \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_dataloader                \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                dataloader = val_dataloader\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward and backward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss_value.item()\n",
    "                running_acc += (preds_class == labels.data).float().mean()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = running_acc / len(dataloader)\n",
    "\n",
    "            if phase == 'train':\n",
    "                hystory_loss_train.append(epoch_loss)\n",
    "                hystory_acc_train.append(epoch_acc)\n",
    "                scheduler.step()\n",
    "            else:\n",
    "                hystory_loss_val.append(epoch_loss)\n",
    "                hystory_acc_val.append(epoch_acc)\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
    "\n",
    "    return hystory_loss_train, hystory_loss_val, hystory_acc_train, hystory_acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latter-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCNc2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SCNc2, self).__init__()\n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(), \n",
    "        )\n",
    "\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),  \n",
    "        )\n",
    "\n",
    "        self.c3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "           \n",
    "        )\n",
    "\n",
    "        self.c4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=8192, out_features=1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=1024, out_features=32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(in_features=32, out_features=2)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        residual_1 = x\n",
    "        out = self.c1(x)\n",
    "        out += residual_1\n",
    "        #print(out.shape)\n",
    "  \n",
    "        # Second block\n",
    "        residual_2 = out\n",
    "        out = self.c2(x)\n",
    "        out += residual_2\n",
    "        \n",
    "        out = self.c3(out)\n",
    "        out = self.c4(out)\n",
    "  \n",
    "        out = out.view(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a32090dc0e482caa5c3465b6b4b7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf61e8d4bef43febc188d4235498b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=166.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "dict_pred = defaultdict(list)\n",
    "file_names = []\n",
    "for line in test_dataset.imgs:\n",
    "    file_names.append(str(line).split('/')[-1].split('.')[0])\n",
    "\n",
    "dict_pred['id'] = file_names\n",
    "\n",
    "for i in trange(8):\n",
    "    set_seed(SEED+i)\n",
    "    \n",
    "    net = SCNc2()\n",
    "    net = net.to(device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adagrad(net.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    hystory_loss_train, hystory_loss_val, hystory_acc_train, hystory_acc_val =\\\n",
    "    train_model(net, loss, optimizer, scheduler, EPOCHS, train_type_loader, val_type_loader);\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax1.plot(hystory_loss_train, label='train')\n",
    "    ax1.plot(hystory_loss_val, label='val')\n",
    "    ax1.legend()\n",
    "\n",
    "    # валидация не показательна\n",
    "    ax2.plot(hystory_acc_train, label='train')\n",
    "    ax2.plot(hystory_acc_val, label='val')\n",
    "    ax2.legend()\n",
    "    \n",
    "    net.eval()\n",
    "    dict_pred[f'SCNc2-{i}'] = []\n",
    "    with torch.no_grad():\n",
    "        for _, (img, name) in enumerate(tqdm(test_loader)):\n",
    "            img = img.to(device)\n",
    "            outputs = net(img)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            predicted = list(map(int, predicted.cpu()))\n",
    "            dict_pred[f'SCNc2-{i}'].extend(predicted)\n",
    "\n",
    "    del net\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_frame = pd.DataFrame.from_dict(dict_pred)\n",
    "#data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_pred['SCNc2-0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_pred['SCNc2-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-charm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-casting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-minimum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-light",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-poster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-substitute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-collector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-dublin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-right",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-medium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-crossing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-degree",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-oakland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-madagascar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-handbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-basement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-tract",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-friday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-desperate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
